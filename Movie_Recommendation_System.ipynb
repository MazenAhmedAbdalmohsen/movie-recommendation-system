{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "ChKtGkOIbN85",
        "outputId": "aa537a7c-b86d-4d2d-d21b-b264b0d0f703"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blosc2 3.5.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "809ba64e96f84ebf9ecae9b387c45784"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPgie5Uwah3i",
        "outputId": "8e0d7348-2ca6-467b-8ba8-84dc0d4b850c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/154.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.15.3)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2469550 sha256=0d40a7db76064ed2b9091023d4bf7a4ec04aa0562e3d07f240e2e56cc3145130\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Verify numpy version\n",
        "print(\"NumPy version:\", np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgH0PaYjbT-w",
        "outputId": "1ab20f8f-e523-4518-fd36-b5869e36d5ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version: 1.24.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gc"
      ],
      "metadata": {
        "id": "Cn-w2845HtAq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Improved memory optimization function\n",
        "def reduce_mem_usage(df):\n",
        "    \"\"\" Iterate through all columns of a dataframe and modify the data type\n",
        "        to reduce memory usage, handling categorical data properly.\n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print(f'Memory usage of dataframe is {start_mem:.2f} MB')\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type == object:\n",
        "            # Convert object columns to category if they have low cardinality\n",
        "            if len(df[col].unique()) / len(df[col]) < 0.5:\n",
        "                df[col] = df[col].astype('category')\n",
        "        elif col_type.name == 'category':\n",
        "            # Skip already categorical columns\n",
        "            continue\n",
        "        else:\n",
        "            # Numeric columns optimization\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print(f'Memory usage after optimization is: {end_mem:.2f} MB')\n",
        "    print(f'Decreased by {100 * (start_mem - end_mem) / start_mem:.1f}%')\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "jQLEaITAdfsX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aZcP4sgUHngL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e8876c-a389-4eb7-ce99-8ae08b8bef7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/parasharmanas/movie-recommendation-system\n",
            "License(s): ODbL-1.0\n",
            "Downloading movie-recommendation-system.zip to /content\n",
            " 50% 83.0M/165M [00:00<00:00, 867MB/s]\n",
            "100% 165M/165M [00:00<00:00, 715MB/s] \n",
            "Archive:  movie-recommendation-system.zip\n",
            "  inflating: movies.csv              \n",
            "  inflating: ratings.csv             \n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d parasharmanas/movie-recommendation-system\n",
        "!unzip movie-recommendation-system.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets with memory optimization\n",
        "print(\"Loading movies data...\")\n",
        "movies_df = pd.read_csv('movies.csv')\n",
        "\n",
        "# Preprocess data before memory optimization\n",
        "movies_df['year'] = movies_df['title'].str.extract(r'\\((\\d{4})\\)')\n",
        "movies_df['year'] = pd.to_numeric(movies_df['year'], errors='coerce')\n",
        "movies_df['clean_title'] = movies_df['title'].str.replace(r'\\(\\d{4}\\)', '').str.strip()"
      ],
      "metadata": {
        "id": "uCutNRXFIGnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb8f4e61-41ab-4ad7-9f7b-8a25a014a0c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading movies data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now apply memory optimization\n",
        "movies_df = reduce_mem_usage(movies_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSTC0EHpeopA",
        "outputId": "30046439-8fd1-4ac7-fea0-1b9b4d0f4344"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage of dataframe is 2.38 MB\n",
            "Memory usage after optimization is: 1.50 MB\n",
            "Decreased by 36.8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLoading ratings data...\")\n",
        "# Load ratings in chunks to manage memory\n",
        "chunksize = 1000000\n",
        "ratings_chunks = pd.read_csv('ratings.csv', chunksize=chunksize)\n",
        "ratings_df = pd.concat([reduce_mem_usage(chunk) for chunk in ratings_chunks])\n",
        "del ratings_chunks\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFrKX3c3bm3S",
        "outputId": "28e56ff1-a6ae-4e51-905e-e52afcf921bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading ratings data...\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 11.44 MB\n",
            "Decreased by 62.5%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 11.44 MB\n",
            "Decreased by 62.5%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 11.44 MB\n",
            "Decreased by 62.5%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 11.44 MB\n",
            "Decreased by 62.5%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 11.44 MB\n",
            "Decreased by 62.5%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 30.52 MB\n",
            "Memory usage after optimization is: 13.35 MB\n",
            "Decreased by 56.2%\n",
            "Memory usage of dataframe is 0.00 MB\n",
            "Memory usage after optimization is: 0.00 MB\n",
            "Decreased by 53.9%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample a subset of the data for faster prototyping\n",
        "print(\"\\nSampling data for faster prototyping...\")\n",
        "sample_frac = 0.1  # Use 10% of data - adjust based on your system's memory\n",
        "ratings_df = ratings_df.sample(frac=sample_frac, random_state=42)\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRE0I7CHbqLx",
        "outputId": "17f87668-827c-49eb-88ee-d281581730ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sampling data for faster prototyping...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for Surprise\n",
        "print(\"\\nPreparing data for modeling...\")\n",
        "reader = Reader(rating_scale=(0.5, 5.0))\n",
        "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sulPEzRb87Q",
        "outputId": "0a000eee-9b9d-46a3-f256-989e1816f9a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preparing data for modeling...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DjW3V8KAd-Go"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build SVD model\n",
        "print(\"\\nTraining SVD model...\")\n",
        "svd = SVD(n_factors=100, n_epochs=30, lr_all=0.007, reg_all=0.05)\n",
        "svd.fit(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3wQ8ry0e-Vw",
        "outputId": "4dc2fe61-cd22-481b-eca4-9894b02f0cad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training SVD model...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7e1b93df1790>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "print(\"\\nEvaluating model...\")\n",
        "predictions = svd.test(testset)\n",
        "print(\"RMSE:\", accuracy.rmse(predictions))\n",
        "print(\"MAE:\", accuracy.mae(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIkrNE3xfA9A",
        "outputId": "77127c82-c367-4465-97a4-d69bd2b02011"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating model...\n",
            "RMSE: 0.8896\n",
            "RMSE: 0.889623385633858\n",
            "MAE:  0.6801\n",
            "MAE: 0.6801035806498711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "print(\"\\nSaving model...\")\n",
        "model_path = 'movie_recommender_svd_model.pkl'\n",
        "joblib.dump(svd, model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZrfSr4IfDxp",
        "outputId": "6a80dd7d-acb0-4bad-dd5c-38850d150ca9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['movie_recommender_svd_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Content-based filtering components\n",
        "print(\"\\nPreparing content-based components...\")\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(movies_df['clean_title'].fillna(''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I9oBNuyfuym",
        "outputId": "35cc9211-26f7-40a3-c150-6197bb3d959b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preparing content-based components...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TF-IDF components\n",
        "joblib.dump(tfidf_matrix, 'tfidf_matrix.pkl')\n",
        "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLdbl8ZSfvW7",
        "outputId": "f911ef31-429b-4dba-c36f-92d82125146c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendation functions\n",
        "def hybrid_recommendations(user_id, title_query=None, n=10):\n",
        "    \"\"\"Hybrid recommendation function combining collaborative and content-based filtering\"\"\"\n",
        "    if title_query:\n",
        "        # Content-based filtering\n",
        "        query_vec = tfidf.transform([title_query])\n",
        "        similarity_scores = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
        "        similar_indices = np.argpartition(similarity_scores, -n)[-n:]\n",
        "        similar_movies = movies_df.iloc[similar_indices][['movieId', 'clean_title']]\n",
        "        similar_movies['predicted_rating'] = similar_movies['movieId'].apply(\n",
        "            lambda x: svd.predict(user_id, x).est\n",
        "        )\n",
        "        return similar_movies.sort_values('predicted_rating', ascending=False).head(n)\n",
        "    else:\n",
        "        # Collaborative filtering\n",
        "        all_movie_ids = ratings_df['movieId'].unique()\n",
        "        rated_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].values\n",
        "        unrated_movies = [mid for mid in all_movie_ids if mid not in rated_movies]\n",
        "\n",
        "        if len(unrated_movies) > 10000:\n",
        "            unrated_movies = np.random.choice(unrated_movies, 10000, replace=False)\n",
        "\n",
        "        predictions = []\n",
        "        for movie_id in unrated_movies:\n",
        "            predictions.append((movie_id, svd.predict(user_id, movie_id).est))\n",
        "\n",
        "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n = predictions[:n]\n",
        "\n",
        "        recommendations = []\n",
        "        for movie_id, pred_rating in top_n:\n",
        "            title = movies_df[movies_df['movieId'] == movie_id]['clean_title'].values[0]\n",
        "            recommendations.append({'title': title, 'predicted_rating': pred_rating})\n",
        "\n",
        "        return pd.DataFrame(recommendations)\n",
        "\n",
        "# Test the system\n",
        "print(\"\\nTesting recommendation system...\")\n",
        "user_id = 1\n",
        "print(f\"\\nTop 10 recommendations for user {user_id}:\")\n",
        "print(hybrid_recommendations(user_id))\n",
        "\n",
        "query = \"Toy Story\"\n",
        "print(f\"\\nMovies similar to '{query}' that user {user_id} might like:\")\n",
        "print(hybrid_recommendations(user_id, title_query=query))\n",
        "\n",
        "print(\"\\nRecommendation system implementation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjCkl96Xfxff",
        "outputId": "4e77b34c-313c-4a81-9de4-b5d29c093747"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing recommendation system...\n",
            "\n",
            "Top 10 recommendations for user 1:\n",
            "                                               title  predicted_rating\n",
            "0                   Shawshank Redemption, The (1994)          4.032677\n",
            "1                         Au Hasard Balthazar (1966)          4.030592\n",
            "2                                        DiG! (2004)          4.029182\n",
            "3            Winter Light (Nattvardsgästerna) (1963)          4.026713\n",
            "4  My Mother's Castle (Château de ma mère, Le) (1...          4.016335\n",
            "5                                 Dersu Uzala (1975)          4.008282\n",
            "6                                Planet Earth (2006)          3.978574\n",
            "7                          Harakiri (Seppuku) (1962)          3.967903\n",
            "8                         Straight Story, The (1999)          3.967163\n",
            "9                                   Inception (2010)          3.961637\n",
            "\n",
            "Movies similar to 'Toy Story' that user 1 might like:\n",
            "       movieId                        clean_title  predicted_rating\n",
            "14813    78499                 Toy Story 3 (2010)          3.438798\n",
            "3021      3114                 Toy Story 2 (1999)          3.429427\n",
            "0            1                   Toy Story (1995)          3.403573\n",
            "59767   201588                 Toy Story 4 (2019)          3.359967\n",
            "24693   122078                The Toy Wife (1938)          3.119101\n",
            "58832   199484                     Toy Gun (2018)          3.119101\n",
            "15157    80141          Christmas Toy, The (1986)          3.119101\n",
            "20497   106022         Toy Story of Terror (2013)          2.966869\n",
            "24064   120474  Toy Story That Time Forgot (2014)          2.948851\n",
            "4823      4929                    Toy, The (1982)          2.711190\n",
            "\n",
            "Recommendation system implementation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BKiDli2HggJe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}